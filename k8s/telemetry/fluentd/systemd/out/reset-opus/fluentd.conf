<source>
  @id reset-test
  @type tail
  path /var/local/logs/reset_tests/*/*/*/*
  pos_file /var/local/logs/reset_tests/reset-test.pos
  format none
  # message_key log
  read_from_head true
  tag reset-test.*
</source>

<source>
  @type monitor_agent
  port 24210
</source>


<filter reset-test.**>
  @type record_transformer
  <record>
# Assuming target path to be of following format: <LOG ROOT>/<TEST NAME>/<RUNID>/<HOST>/<LOGFILE>.<EXT>
# Assuming LOGFILE doesn't have a '.' in it
    host ${tag_parts[-3]}
    runid ${tag_parts[-4]}
    test ${tag_parts[-5]}
  </record>
</filter>


<match reset-test.**>
 @type kafka2
 @log_level info

 brokers 10.250.0.130:31090,10.250.0.131:31091,10.250.0.134:31092,
 default_topic atscale-other
# Setting kafka create time to event time. Supports only upto millisecond resolution
 use_event_time true
 
 # ruby-kafka configuration
 max_send_limit_bytes 10485760
 # kafka_agg_max_bytes 10485760
 # kafka_agg_max_messages 5000
 get_kafka_client_log true
 compression_codec snappy
 idempotent true

 <format>
  @type json
 </format>

 <inject>
  tag_key tag
# Preserve nanosecond time timestamp in 'logtime' field
  time_key logtime
  time_type string
  time_format %Y-%m-%dT%H:%M:%S.%NZ
 </inject>
 
 <buffer tag>
  @type file
  path /root/fluentd-kafka-buffer
  flush_mode interval
  retry_type exponential_backoff
  flush_thread_count 3
  flush_interval 30s
  retry_timeout 1h
  retry_max_interval 120000
  chunk_limit_size 10M
  queue_limit_length 8
  overflow_action block
 </buffer>
</match>
